random_seed = 42
fast_dev_run = false
regenerate = false
pretrain = false
finetune = false
evaluate = false
profile = false
train_size = 0.8
monitor = "val_loss"
mode = "min"

[filepaths]
data = "data/datasets/sentiment_analysis.csv"
train = "data/datasets/train.csv"
val = "data/datasets/val.csv"
test = "data/datasets/test.csv"
pretrain_checkpoints = "data/pretrain_checkpoints"
finetune_checkpoints = "data/finetune_checkpoints"
logs = "data/lightning_logs"

[model]
[model.pretrain]
embedding_dim = 512
[model.finetune]
hidden_dim = 256
output_dim = 1
freeze = true
random_embeddings = false

[optimizer]
[optimizer.pretrain]
lr = 1.0
weight_decay = 0.0
[optimizer.finetune]
lr = 0.1
weight_decay = 1e-10
[optimizer.shared]
momentum = 0.99
nesterov = true

[training]
batch_size = 512
max_epochs = 100
gradient_clip = 1.0
early_stopping_patience = 2
# 1/4 of a day, 2 words, 10 words, 1 tweet identity 
sigma = [0.25, 2.0, 10.0, 1.0]                 
n_negatives = 10

[scheduler]
patience = 1
factor = 0.1

[logging]
val_check_interval = 1000
check_val_every_n_epoch = 1
log_every_n_steps = 1000
